# pdf-toc
Table of Contents for PDF files of scientific papers
# ğŸ§  GÃ©nÃ©ration de sommaires Ã  partir de documents scientifiques (PDF)

Ce projet s'inscrit dans le cadre d'une Ã©tude de cas, visant Ã  explorer diffÃ©rentes approches pour extraire automatiquement des **sommaires** (et Ã©ventuellement des rÃ©sumÃ©s de sections) Ã  partir d'articles scientifiques disponibles sur [arXiv.org](https://arxiv.org/list/cs.AI/recent), au format PDF.

L'objectif est de dÃ©montrer une **capacitÃ© Ã  structurer une rÃ©flexion**, Ã  analyser les rÃ©sultats obtenus et Ã  proposer des solutions pertinentes.

---

## ğŸ¯ Objectif

- GÃ©nÃ©rer automatiquement un **sommaire structurÃ©** Ã  partir dâ€™un PDF.
- (Optionnel) GÃ©nÃ©rer un court **rÃ©sumÃ© pour chaque section**.
- Explorer diffÃ©rentes **approches heuristiques et basÃ©es sur des modÃ¨les de langage**.
- Identifier les limites de chaque solution pour justifier les choix techniques.

---

## ğŸ§  DÃ©marche

### 1. ComprÃ©hension du problÃ¨me
- Identifier les sections, sous-sections et hiÃ©rarchies dans les articles scientifiques.
- Traiter la diversitÃ© des formats de titres (ex. : `1 Introduction`, `2.1 Travaux connexes`, titres en majuscules, etc.).
- Traiter la diversitÃ© des formats de documents PDF (double colonne, police, etc.)
- Structuration sous forme de sommaire hiÃ©rarchique.

### 2. Veille technologique
Avant de dÃ©marrer le dÃ©veloppement, plusieurs outils et bibliothÃ¨ques ont Ã©tÃ© explorÃ©s pour Ã©valuer leur pertinence dans le cadre de la gÃ©nÃ©ration de sommaires Ã  partir de PDF scientifiques :

| Outil / Approche               | Description                                                                 | Statut dans ce projet       | Observations |
|-------------------------------|-----------------------------------------------------------------------------|------------------------------|--------------|
| **GROBID**                    | Extraction structurÃ©e des mÃ©tadonnÃ©es et sections (Java + Docker)           | âŒ Non utilisÃ©                | Installation Ã©chouÃ©e malgrÃ© plusieurs tentatives. TrÃ¨s adaptÃ© sur le fond. |
| **LangChain + Unstructured**  | Chargement de PDF en blocs logiques (titres, paragraphes, tableaux, etc.)  | âŒ Trop instable             | Erreurs multiples liÃ©es aux dÃ©pendances. IntÃ©ressant mais fragile. |
| **LayoutParser**              | Analyse visuelle des layouts (via OCR et dÃ©tection de blocs)                | âš ï¸ Partiellement adaptÃ©      | Mieux adaptÃ© aux documents visuels quâ€™aux textes structurÃ©s. |
| **LLMs Hugging Face**         | Utilisation de modÃ¨les comme BART, T5 pour classifier ou gÃ©nÃ©rer des TOC    | âœ… UtilisÃ© Ã  titre comparatif | Faciles Ã  intÃ©grer, rÃ©sultats variables, structure parfois imprÃ©cise. |
| **GPT-4o (OpenAI)**           | Extraction de TOC par prompt sur chaque page avec structuration JSON        | âœ… MÃ©thode principale retenue | RÃ©sultats fiables, hiÃ©rarchie respectÃ©e, bon compromis simplicitÃ©/prÃ©cision. |


### 3. ImplÃ©mentation par itÃ©rations

#### ğŸ›  Approche 1 : Extraction heuristique

##### ğŸ”§ ImplÃ©mentation
- Extraction du texte via `pdfplumber` ou `PyMuPDF`.
- DÃ©tection de titres par regex :
  - NumÃ©rotation (`1.`, `1.1.`, "I", "X.")
  - Majuscules
  - DÃ©but de ligne avec majuscule
  - Fin de ligne sans ponctuation
- Structuration hiÃ©rarchique des titres.
##### âš ï¸ Limites
- Sensible Ã  la diversitÃ© des formats PDF (mise en page, colonnes, polices...).
- Trop de rÃ¨gles (regex) risquent dâ€™Ã©liminer de vrais titres ; trop peu en dÃ©tectent de faux.
- Ne permet pas de capturer tous les styles ou formats de titres possibles.
- Confond souvent les titres avec des listes numÃ©rotÃ©es.
- Ne tient pas compte des styles typographiques (gras, taille, indentation).
- Ne gÃ¨re pas les documents multilingues ou contenant des symboles atypiques.

#### ğŸ¤– Approche 2 : Utilisation de modÃ¨les de langage (LLM)
##### ğŸ”§ ImplÃ©mentation
- Lecture du PDF **page par page** via `PyMuPDF` pour rÃ©duire la taille des prompts.
- Envoi de chaque page Ã  un **LLM** (ex. `GPT-4o`) via lâ€™API OpenAI.
- GÃ©nÃ©ration directe dâ€™un JSON structurÃ© contenant les titres de sections dÃ©tectÃ©s.
- Nettoyage des rÃ©ponses : filtrage du format, validation JSON, gestion des erreurs.
- Sauvegarde intermÃ©diaire aprÃ¨s chaque page pour Ã©viter la perte de donnÃ©es.

##### âš ï¸ Limites
- **CoÃ»t et quota API** : les appels multiples Ã  lâ€™API GPT-4 peuvent dÃ©passer les quotas (TPM), notamment sur des documents longs.
- **Longueur des prompts** : certains contenus dÃ©passent les limites autorisÃ©es (~30k tokens/min pour GPT-4o), ce qui peut provoquer des erreurs 429.
- **VariabilitÃ© des rÃ©ponses** : les formats retournÃ©s par les LLM ne sont pas toujours strictement conformes au format attendu â†’ besoin de post-traitement.
- **Latence cumulÃ©e** : traitement long lorsquâ€™on parcourt plusieurs documents page par page, mÃªme avec des `sleep()` optimisÃ©s.



#### ğŸ”¬ Approche 3 : Classification / BERT
##### ğŸ”§ ImplÃ©mentation
- Classifier chaque ligne comme "titre de section" ou "texte normal".
- PossibilitÃ© dâ€™intÃ©grer LayoutLM ou SciBERT pour amÃ©liorer la prÃ©cision.

##### âš ï¸ Limites
---

## ğŸ“Š Ã‰valuation & perspectives

- Chaque mÃ©thode a Ã©tÃ© testÃ©e sur des exemples rÃ©els (arXiv).
- Les rÃ©sultats ont Ã©tÃ© analysÃ©s en termes de :
  - PrÃ©cision des titres dÃ©tectÃ©s
  - Structuration hiÃ©rarchique
  - RÃ©silience face aux mises en page variÃ©es

### ğŸ”­ AmÃ©liorations envisagÃ©es
- IntÃ©gration dâ€™un **graphe de connaissances** pour reprÃ©senter les relations entre sections, et la structure complÃ¨te du document.
- Fine-tuning dâ€™un modÃ¨le sur un corpus dâ€™articles scientifiques.
- GÃ©nÃ©ration automatique de rÃ©sumÃ©s par section.
- Interface utilisateur ou pipeline RAG.

---

## ğŸ“ Arborescence du projet
```bash
â”œâ”€â”€ notebook.ipynb         # Notebook principal avec l'ensemble des expÃ©rimentations
â”œâ”€â”€ README.md              # Documentation du projet
â”œâ”€â”€ .env                   # Fichier de configuration (clÃ© API, ignorÃ© par Git)
â”œâ”€â”€ articles/              # Dossier contenant les PDF extraits de arXiv
â”œâ”€â”€ output_v1/             # RÃ©sultats de l'approche 1 (regex + heuristiques)
â”œâ”€â”€ output_v2/             # RÃ©sultats de l'approche 2 (LLM, GPT-4o)
â””â”€â”€ requirements.txt       # Liste des dÃ©pendances
```